# Interpretability vs Performance


In financial machine learning, there is a persistent tension between **model interpretability** and **predictive performance**. Managing this trade-off is central to responsible model deployment.

---

## What is interpretability?


Interpretability refers to the ability to:
- understand how inputs affect outputs,
- explain model decisions to stakeholders,
- diagnose errors and instability.

Linear and sparse models are typically highly interpretable.

---

## Performance-driven models


High-performance models include:
- deep neural networks,
- ensemble methods,
- highly nonlinear learners.

They often achieve superior predictive accuracy but operate as black boxes.

---

## Financial and regulatory context


In finance:
- models affect capital, pricing, and risk limits,
- regulators require explainability,
- senior management must understand model behavior.

Pure black-box approaches are often unacceptable.

---

## Practical trade-offs


Institutions balance:
- slightly lower accuracy for higher transparency,
- model simplicity for robustness,
- explainability for governance and trust.

Interpretability is a form of risk control.

---

## Key takeaways


- Interpretability and performance often conflict.
- Finance prioritizes explainability and stability.
- Model choice reflects governance constraints.

---

## Further reading


- Rudin, interpretable machine learning.
- Molnar, *Interpretable Machine Learning*.
