# Interpretability vs Performance

In financial machine learning, there is a persistent tension between **model interpretability** and **predictive performance**. Managing this trade-off is central to responsible model deployment.

---

## 1. What is interpretability?

Interpretability refers to the ability to:
- understand how inputs affect outputs,
- explain model decisions to stakeholders,
- diagnose errors and instability.

Linear and sparse models are typically highly interpretable.

---

## 2. Performance-driven models

High-performance models include:
- deep neural networks,
- ensemble methods,
- highly nonlinear learners.

They often achieve superior predictive accuracy but operate as black boxes.

---

## 3. Financial and regulatory context

In finance:
- models affect capital, pricing, and risk limits,
- regulators require explainability,
- senior management must understand model behavior.

Pure black-box approaches are often unacceptable.

---

## 4. Practical trade-offs

Institutions balance:
- slightly lower accuracy for higher transparency,
- model simplicity for robustness,
- explainability for governance and trust.

Interpretability is a form of risk control.

---

## 5. Key takeaways

- Interpretability and performance often conflict.
- Finance prioritizes explainability and stability.
- Model choice reflects governance constraints.

---

## Further reading

- Rudin, interpretable machine learning.
- Molnar, *Interpretable Machine Learning*.
